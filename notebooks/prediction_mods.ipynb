{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN time\n",
    "\n",
    "### For this dataset we are going with a DNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "['NVIDIA GeForce RTX 4070']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "devices = [d for d in range(torch.cuda.device_count())]\n",
    "device_names = [torch.cuda.get_device_name(d) for d in devices]\n",
    "print(device_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../data/final_dataset_1.csv')\n",
    "\n",
    "X = data.drop('price', axis=1).values\n",
    "y = data['price'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the model and its losing and optimizing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(X_train.shape[1], 128)\n",
    "        self.dropout = nn.Dropout(0.5)  # Dropout layer\n",
    "        self.layer2 = nn.Linear(128, 256)\n",
    "        self.output_layer = nn.Linear(256, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.dropout(x)  # Applying dropout\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = DNN().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 173298188288.0000\n",
      "Epoch [2/100], Loss: 330616373248.0000\n",
      "Epoch [3/100], Loss: 109847543808.0000\n",
      "Epoch [4/100], Loss: 18622097408.0000\n",
      "Epoch [5/100], Loss: 17073433600.0000\n",
      "Epoch [6/100], Loss: 15711789056.0000\n",
      "Epoch [7/100], Loss: 75779039232.0000\n",
      "Epoch [8/100], Loss: 11137985536.0000\n",
      "Epoch [9/100], Loss: 32038959104.0000\n",
      "Epoch [10/100], Loss: 89955262464.0000\n",
      "Epoch [11/100], Loss: 101630795776.0000\n",
      "Epoch [12/100], Loss: 5411389440.0000\n",
      "Epoch [13/100], Loss: 15290548224.0000\n",
      "Epoch [14/100], Loss: 35948462080.0000\n",
      "Epoch [15/100], Loss: 16064856064.0000\n",
      "Epoch [16/100], Loss: 8164881920.0000\n",
      "Epoch [17/100], Loss: 21355747328.0000\n",
      "Epoch [18/100], Loss: 14851836928.0000\n",
      "Epoch [19/100], Loss: 44966719488.0000\n",
      "Epoch [20/100], Loss: 9203366912.0000\n",
      "Epoch [21/100], Loss: 58826772480.0000\n",
      "Epoch [22/100], Loss: 20981432320.0000\n",
      "Epoch [23/100], Loss: 64444858368.0000\n",
      "Epoch [24/100], Loss: 5206033408.0000\n",
      "Epoch [25/100], Loss: 146199838720.0000\n",
      "Epoch [26/100], Loss: 25174421504.0000\n",
      "Epoch [27/100], Loss: 11572001792.0000\n",
      "Epoch [28/100], Loss: 66634358784.0000\n",
      "Epoch [29/100], Loss: 7732503552.0000\n",
      "Epoch [30/100], Loss: 8409994240.0000\n",
      "Epoch [31/100], Loss: 17079890944.0000\n",
      "Epoch [32/100], Loss: 13076473856.0000\n",
      "Epoch [33/100], Loss: 13863895040.0000\n",
      "Epoch [34/100], Loss: 9641556992.0000\n",
      "Epoch [35/100], Loss: 12447605760.0000\n",
      "Epoch [36/100], Loss: 22167885824.0000\n",
      "Epoch [37/100], Loss: 30223613952.0000\n",
      "Epoch [38/100], Loss: 33319917568.0000\n",
      "Epoch [39/100], Loss: 51036160000.0000\n",
      "Epoch [40/100], Loss: 16967949312.0000\n",
      "Epoch [41/100], Loss: 24224681984.0000\n",
      "Epoch [42/100], Loss: 17936222208.0000\n",
      "Epoch [43/100], Loss: 21217826816.0000\n",
      "Epoch [44/100], Loss: 55556386816.0000\n",
      "Epoch [45/100], Loss: 10982601728.0000\n",
      "Epoch [46/100], Loss: 44859117568.0000\n",
      "Epoch [47/100], Loss: 23249381376.0000\n",
      "Epoch [48/100], Loss: 28271491072.0000\n",
      "Epoch [49/100], Loss: 32853678080.0000\n",
      "Epoch [50/100], Loss: 27320100864.0000\n",
      "Epoch [51/100], Loss: 14883432448.0000\n",
      "Epoch [52/100], Loss: 8988498944.0000\n",
      "Epoch [53/100], Loss: 4433952256.0000\n",
      "Epoch [54/100], Loss: 14727798784.0000\n",
      "Epoch [55/100], Loss: 18716137472.0000\n",
      "Epoch [56/100], Loss: 6269146112.0000\n",
      "Epoch [57/100], Loss: 18378110976.0000\n",
      "Epoch [58/100], Loss: 13303622656.0000\n",
      "Epoch [59/100], Loss: 99685163008.0000\n",
      "Epoch [60/100], Loss: 19992856576.0000\n",
      "Epoch [61/100], Loss: 30027386880.0000\n",
      "Epoch [62/100], Loss: 31362234368.0000\n",
      "Epoch [63/100], Loss: 26179987456.0000\n",
      "Epoch [64/100], Loss: 5120962560.0000\n",
      "Epoch [65/100], Loss: 6865689088.0000\n",
      "Epoch [66/100], Loss: 4181331968.0000\n",
      "Epoch [67/100], Loss: 3146121216.0000\n",
      "Epoch [68/100], Loss: 17858953216.0000\n",
      "Epoch [69/100], Loss: 242847236096.0000\n",
      "Epoch [70/100], Loss: 39869485056.0000\n",
      "Epoch [71/100], Loss: 12263135232.0000\n",
      "Epoch [72/100], Loss: 6549382144.0000\n",
      "Epoch [73/100], Loss: 20570753024.0000\n",
      "Epoch [74/100], Loss: 5549315584.0000\n",
      "Epoch [75/100], Loss: 119365459968.0000\n",
      "Epoch [76/100], Loss: 7535306240.0000\n",
      "Epoch [77/100], Loss: 122942513152.0000\n",
      "Epoch [78/100], Loss: 17011629056.0000\n",
      "Epoch [79/100], Loss: 4352818176.0000\n",
      "Epoch [80/100], Loss: 25601050624.0000\n",
      "Epoch [81/100], Loss: 16780295168.0000\n",
      "Epoch [82/100], Loss: 18534674432.0000\n",
      "Epoch [83/100], Loss: 15466896384.0000\n",
      "Epoch [84/100], Loss: 4027502336.0000\n",
      "Epoch [85/100], Loss: 19512709120.0000\n",
      "Epoch [86/100], Loss: 8194813440.0000\n",
      "Epoch [87/100], Loss: 14425876480.0000\n",
      "Epoch [88/100], Loss: 20716507136.0000\n",
      "Epoch [89/100], Loss: 113505165312.0000\n",
      "Epoch [90/100], Loss: 4130111488.0000\n",
      "Epoch [91/100], Loss: 63876169728.0000\n",
      "Epoch [92/100], Loss: 11393258496.0000\n",
      "Epoch [93/100], Loss: 368970301440.0000\n",
      "Epoch [94/100], Loss: 6978449408.0000\n",
      "Epoch [95/100], Loss: 31404134400.0000\n",
      "Epoch [96/100], Loss: 5331491328.0000\n",
      "Epoch [97/100], Loss: 30872588288.0000\n",
      "Epoch [98/100], Loss: 1843325312.0000\n",
      "Epoch [99/100], Loss: 50244366336.0000\n",
      "Epoch [100/100], Loss: 5267113472.0000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "model.train()  \n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE Loss: 31791507456.0000\n",
      "Test RMSE Loss: 178301.7344\n",
      "Test MAE Loss: 114020.2109\n",
      "R-squared Score: 0.6714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient calculation for evaluation\n",
    "with torch.no_grad():\n",
    "    inputs, targets = X_test.to(device), y_test.to(device)\n",
    "    predictions = model(inputs)\n",
    "\n",
    "    # Calculating different metrics\n",
    "    mse_loss = criterion(predictions, targets)  # MSE\n",
    "    rmse_loss = torch.sqrt(mse_loss)            # RMSE\n",
    "    mae_loss = torch.mean(torch.abs(predictions - targets))  # MAE\n",
    "    r2 = r2_score(targets.cpu().numpy(), predictions.cpu().numpy())  # R2 score\n",
    "\n",
    "    # Printing the metrics\n",
    "    print(f'Test MSE Loss: {mse_loss.item():.4f}')\n",
    "    print(f'Test RMSE Loss: {rmse_loss.item():.4f}')\n",
    "    print(f'Test MAE Loss: {mae_loss.item():.4f}')\n",
    "    print(f'R-squared Score: {r2:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "df = pd.read_csv('../data/final_dataset_1.csv')\n",
    "\n",
    "# Assuming df is your DataFrame and 'price' is the target variable\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "clf = GradientBoostingRegressor(n_estimators = 700, max_depth = 7, min_samples_split = 3, learning_rate = 0.1)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 30194992032.6178\n",
      "Mean Absolute Error: 103340.4322\n",
      "R-squared: 0.7019\n"
     ]
    }
   ],
   "source": [
    "# Add new metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mse = mean_squared_error(y_test, Y_pred)\n",
    "mae = mean_absolute_error(y_test, Y_pred)\n",
    "r2 = r2_score(y_test, Y_pred)\n",
    "#accuracy = accuracy_score(y_test, Y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print(f'Mean Absolute Error: {mae:.4f}')\n",
    "print(f'R-squared: {r2:.4f}')\n",
    "#print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Create an XGBoost regressor\n",
    "model = XGBRegressor(objective='reg:squarederror', random_state=2)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "Y_pred = model.predict(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IC_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
